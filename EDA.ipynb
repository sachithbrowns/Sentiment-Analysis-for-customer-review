{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Profiling (EDA)\n",
    "\n",
    "1. Check for missing values.\n",
    "\n",
    "2. Identify data types.\n",
    "\n",
    "3. Detect duplicates.\n",
    "\n",
    "4. Perform summary statistics for numerical & categorical columns.\n",
    "\n",
    "5. Analyze distribution of ratings and customer feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SachithN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SachithN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SachithN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download necessary NLTK datasets\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"EDA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install missingno\n",
    "import missingno as msno\n",
    "\n",
    "# Convert date columns to datetime\n",
    "df['CreatedOn'] = pd.to_datetime(df['CreatedOn'], errors='coerce')\n",
    "\n",
    "# Display missing values heatmap\n",
    "msno.matrix(df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FeedbackCode</th>\n",
       "      <th>FeedbackId</th>\n",
       "      <th>DivisionName</th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>ContactNo</th>\n",
       "      <th>Location</th>\n",
       "      <th>Designation</th>\n",
       "      <th>JobNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>IsRecommended</th>\n",
       "      <th>Review</th>\n",
       "      <th>ReviewAny</th>\n",
       "      <th>CreatedOn</th>\n",
       "      <th>CreatedBy</th>\n",
       "      <th>DeletedBy</th>\n",
       "      <th>DeletedOn</th>\n",
       "      <th>UpdatedBy</th>\n",
       "      <th>UpdatedOn</th>\n",
       "      <th>IsActive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [FeedbackCode, FeedbackId, DivisionName, InvoiceNo, CustomerId, CustomerName, ContactNo, Location, Designation, JobNumber, How satisfied are you with the service/product quality?, How satisfied are you with the behavior of the service / sales person?, How likely would you recommend Browns products & services to others?, How would you rate the overall experience of the service provided by Browns?, AverageScrore, IsRecommended, Review, ReviewAny, CreatedOn, CreatedBy, DeletedBy, DeletedOn, UpdatedBy, UpdatedOn, IsActive]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing values\n",
    "missing_values = df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "drop_columns = ['DeletedBy', 'DeletedOn', 'UpdatedBy', 'UpdatedOn', 'IsActive']\n",
    "df = df.drop(columns=drop_columns, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SachithN\\AppData\\Local\\Temp\\ipykernel_11596\\888139176.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CustomerName'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\SachithN\\AppData\\Local\\Temp\\ipykernel_11596\\888139176.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Location'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\SachithN\\AppData\\Local\\Temp\\ipykernel_11596\\888139176.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ReviewAny'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Handle missing values\n",
    "df['CustomerName'].fillna('Unknown', inplace=True)\n",
    "df['Location'].fillna('Unknown', inplace=True)\n",
    "df['ReviewAny'].fillna('', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing numerical values with median\n",
    "num_cols = ['Rate', 'RateofSatisfyService', 'RateofTimeTaken', 'RateofServiceProduct']\n",
    "for col in num_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append('/custom/path/to/nltk_data')\n",
    "nltk.download('punkt', download_dir='/custom/path/to/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure 'Cleaned_Review' exists; if not, create it using 'ReviewAny'\n",
    "if 'Cleaned_Review' not in df.columns:\n",
    "\tdf['Cleaned_Review'] = df['ReviewAny']\n",
    "\n",
    "# Generate a Word Cloud for Reviews\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(df['Cleaned_Review']))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud of Customer Reviews\")\n",
    "plt.show()\n",
    "\n",
    "# Sentiment Analysis using TextBlob\n",
    "df['Sentiment'] = df['Cleaned_Review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['Sentiment_Label'] = df['Sentiment'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
    "\n",
    "# Display correlation heatmap (using actual rating columns)\n",
    "rating_cols = [\n",
    "\t'How satisfied are you with the service/product quality?', \n",
    "\t'How satisfied are you with the behavior of the service / sales person?', \n",
    "\t'How likely would you recommend Browns products & services to others?', \n",
    "\t'How would you rate the overall experience of the service provided by Browns?'\n",
    "]\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(df[rating_cols].corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap of Ratings\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"preprocessed_feedback_data.csv\", index=False)\n",
    "print(\"Data saved as preprocessed_feedback_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning & Preprocessing\n",
    "1. Handle missing values:\n",
    "For numerical columns â†’ fill with mean/median.\n",
    "For categorical columns â†’ fill with mode or \"Unknown\".\n",
    "For text (review comments) â†’ drop if empty or use placeholder.\n",
    "\n",
    "2. Convert date columns (CreatedOn) to datetime format.\n",
    "\n",
    "3. Drop irrelevant columns like DeletedBy, DeletedOn (if all null or not needed).\n",
    "\n",
    "4. Standardize text data in ReviewAny (lowercasing, punctuation removal, stopwords removal).\n",
    "\n",
    "5. Convert categorical data to numeric encoding (if needed for ML models).\n",
    "\n",
    "6. Check for outliers in ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_feedback_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percentage of null values for each column in the DataFrame\n",
    "null_percentage = df.isnull().mean() * 100\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handle missing values\n",
    "\n",
    "# For numerical rating columns, fill missing values with the median.\n",
    "for rating in rating_cols:\n",
    "    if rating in df.columns:\n",
    "        df[rating].fillna(df[rating].median(), inplace=True)\n",
    "\n",
    "# For categorical columns (except for review texts and dates), fill missing values with the mode.\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "for col_cat in categorical_cols:\n",
    "    if col_cat not in ['ReviewAny', 'Cleaned_Review', 'CreatedOn']:\n",
    "        if df[col_cat].isnull().sum() > 0:\n",
    "            mode_val = df[col_cat].mode()[0] if not df[col_cat].mode().empty else \"Unknown\"\n",
    "            df[col_cat].fillna(mode_val, inplace=True)\n",
    "\n",
    "# For text review columns, fill empty or missing entries with a placeholder.\n",
    "if 'ReviewAny' in df.columns:\n",
    "    df['ReviewAny'] = df['ReviewAny'].apply(lambda x: x if isinstance(x, str) and x.strip() != \"\" else \"No review provided\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Convert 'CreatedOn' to datetime format.\n",
    "if 'CreatedOn' in df.columns:\n",
    "    df['CreatedOn'] = pd.to_datetime(df['CreatedOn'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Drop irrelevant columns if they exist.\n",
    "irrelevant = ['DeletedBy', 'DeletedOn', 'UpdatedBy', 'UpdatedOn', 'IsActive']\n",
    "df.drop(columns=[col for col in irrelevant if col in df.columns], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Convert categorical columns to numeric encoding where appropriate.\n",
    "# We'll factorize object columns (excluding date and review texts) that have a relatively small number of unique values.\n",
    "for col_cat in df.select_dtypes(include='object').columns:\n",
    "    if col_cat not in ['CreatedOn', 'ReviewAny', 'Cleaned_Review']:\n",
    "        if df[col_cat].nunique() < 100:  # arbitrary threshold for categorical encoding\n",
    "            df[col_cat], _ = pd.factorize(df[col_cat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Check for outliers in the ratings using boxplots.\n",
    "for rating in rating_cols:\n",
    "    if rating in df.columns:\n",
    "        plt.figure()\n",
    "        sns.boxplot(x=df[rating])\n",
    "        plt.title(f\"Boxplot for {rating}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Sentiment Analysis Preprocessing\n",
    "1. Use NLP techniques to prepare text for analysis:\n",
    "2. Tokenization\n",
    "3. Stopword removal\n",
    "4. Lemmatization\n",
    "5. Apply sentiment scoring (VADER, TextBlob) for text reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vaderSentiment\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load the preprocessed feedback data\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure necessary NLTK resources are available\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize NLP tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Stopword removal\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "df = pd.read_csv(\"preprocessed_feedback_data.csv\")\n",
    "# Apply preprocessing\n",
    "df['Cleaned_Review'] = df['ReviewAny'].apply(preprocess_text)\n",
    "\n",
    "# Apply sentiment scoring (TextBlob only)\n",
    "df['TextBlob_Sentiment'] = df['Cleaned_Review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Categorize sentiment\n",
    "df['Sentiment_Label'] = df['TextBlob_Sentiment'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CSV saved as data4final.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('data4final.csv', index=False)\n",
    "print(\"Final CSV saved as data4final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
